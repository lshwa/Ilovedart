{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d20e018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------\n",
    "# 0. 라이브러리\n",
    "# -------------------------------------------------\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c74bd9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------\n",
    "# 1. 데이터 로드\n",
    "# -------------------------------------------------\n",
    "train      = pd.read_csv(\"C:/Users/zzaer/OneDrive/바탕 화면/2025 채린/아러다/train.csv\")              # 학습 데이터\n",
    "test       = pd.read_csv(\"C:/Users/zzaer/OneDrive/바탕 화면/2025 채린/아러다/test.csv\")               # 테스트 데이터\n",
    "sample_sub = pd.read_csv(\"C:/Users/zzaer/OneDrive/바탕 화면/2025 채린/아러다/sample_submission.csv\")  # id 포함 템플릿\n",
    "\n",
    "LABEL_COL = \"fraud\"   # 정답 컬럼\n",
    "ID_COL    = \"id\"      # ID   컬럼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d654690e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------\n",
    "# 2. 단순 전처리\n",
    "# -------------------------------------------------\n",
    "feature_cols = [c for c in train.columns if c not in [LABEL_COL, ID_COL]]\n",
    "\n",
    "# 수치형·범주형 구분\n",
    "num_cols = train[feature_cols].select_dtypes(include=[\"number\"]).columns\n",
    "cat_cols = [c for c in feature_cols if c not in num_cols]\n",
    "\n",
    "# (1) 결측치 채우기\n",
    "train[num_cols] = train[num_cols].fillna(train[num_cols].median())\n",
    "test[num_cols]  = test[num_cols].fillna(train[num_cols].median())\n",
    "\n",
    "for c in cat_cols:\n",
    "    mode_val = train[c].mode().iloc[0]\n",
    "    train[c] = train[c].fillna(mode_val)\n",
    "    test[c]  = test[c].fillna(mode_val)\n",
    "\n",
    "# (2) 범주형 원‑핫 인코딩\n",
    "train_enc = pd.get_dummies(train[feature_cols], drop_first=True)\n",
    "test_enc  = pd.get_dummies(test[feature_cols],  drop_first=True)\n",
    "\n",
    "# train / test 컬럼 맞추기\n",
    "test_enc = test_enc.reindex(columns=train_enc.columns, fill_value=0)\n",
    "\n",
    "X, y = train_enc, train[LABEL_COL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23cb5317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6216, number of negative: 553784\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069205 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3227\n",
      "[LightGBM] [Info] Number of data points in the train set: 560000, number of used features: 46\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.011100 -> initscore=-4.489648\n",
      "[LightGBM] [Info] Start training from score -4.489648\n",
      "Validation Average Precision : 0.163670\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 3. 검증 (80 : 20)\n",
    "# -------------------------------------------------\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "model = LGBMClassifier(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=31,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "model.fit(X_tr, y_tr)\n",
    "\n",
    "val_probs = model.predict_proba(X_val)[:, 1]\n",
    "val_ap = average_precision_score(y_val, val_probs)\n",
    "print(f\"Validation Average Precision : {val_ap:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3252add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 7770, number of negative: 692230\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.057778 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3228\n",
      "[LightGBM] [Info] Number of data points in the train set: 700000, number of used features: 46\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.011100 -> initscore=-4.489648\n",
      "[LightGBM] [Info] Start training from score -4.489648\n",
      "submission.csv 저장 완료\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------\n",
    "# 4. 전체 학습 후 제출 파일 생성\n",
    "# -------------------------------------------------\n",
    "model.fit(X, y)\n",
    "\n",
    "test_probs = model.predict_proba(test_enc)[:, 1]\n",
    "submission = sample_sub.copy()\n",
    "submission[LABEL_COL] = test_probs\n",
    "submission.to_csv(\"C:/Users/zzaer/OneDrive/바탕 화면/2025 채린/아러다/submission.csv\", index=False)\n",
    "print(\"submission.csv 저장 완료\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
